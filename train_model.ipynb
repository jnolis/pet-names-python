{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet Names (Python)\n",
    "\n",
    "This trains a neural network with Keras that generates pet names. It saves the neural to a file at the end, to use in a function in a separate notebook.\n",
    "\n",
    "First, load up the appropriate TensorFlow and other libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create some lookups and variables. The character list is the set of characters to use in the names. The lookup is that converted into a dictionary of integers for encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list = list(string.ascii_lowercase) + [\".\",\"-\",\" \",\"+\"]\n",
    "character_lookup = dict(zip(character_list, range(len(character_list))))\n",
    "max_length = 10\n",
    "num_characters = len(character_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the data, converts it to lower case, and removes any pet that doesn't have a name or species (or the name has invalid characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pet_data():\n",
    "    \"\"\"Load the pet data\n",
    "    This loads the pet data from the csv file and cleans it appropriately.\n",
    "    It removes extra columns, rows with malformed names or breeds, and makes the names\n",
    "    lowercase.\n",
    "    \"\"\"\n",
    "    pet_data = (pd.read_csv(\"seattle_pet_licenses.csv\", dtype = {\"Animal's Name\": str, 'Species': str,'Primary Breed': str,\n",
    "                                                        'Secondary Breed': str},\n",
    "                                                        usecols=[\"Animal's Name\",'Species',\n",
    "                                                        'Primary Breed','Secondary Breed'])\n",
    "                    .rename(columns = {\"Animal's Name\":\"name\",\n",
    "                     \"Species\": \"species\",\n",
    "                     \"Primary Breed\": \"primary_breed\",\n",
    "                     \"Secondary Breed\": \"secondary_breed\"})\n",
    "                    .dropna(subset=['name', 'species']))\n",
    "\n",
    "    for column in pet_data.columns:\n",
    "        pet_data[column] = pet_data[column].str.lower()\n",
    "\n",
    "    pet_data = pet_data[pet_data[\"name\"].str.match(\"^[ \\\\.a-z-]+$\")]\n",
    "\n",
    "    return pet_data\n",
    "\n",
    "pet_data = load_pet_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below:\n",
    "\n",
    "1. Has a function that converts the DataFrame into a list of objects, where each object has some metadata plus the list of subsequences (partials of the name string. So like \"spot\", has [\"s\", \"sp\", \"spo\", \"spot\", \"spot+\"])\n",
    "2. Grabs the subsequences, which then are a list of lists, and flattens them into a single list.\n",
    "3. Stores that list as a new column in the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subsequences(name):\n",
    "    characters = name + '+'\n",
    "    subsequences = [list(characters[0:(i+1)]) for i in range(len(characters))]\n",
    "    return subsequences\n",
    "\n",
    "def get_all_subsequences(pet_data):\n",
    "    subsequences = pet_data[\"name\"].map(make_subsequences)\n",
    "    return subsequences\n",
    "\n",
    "pet_data['subsequences'] = get_all_subsequences(pet_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pull the subsequences, shuffle them, convert the characters to ints using the lookup, pad them, and one hot encode them. You could also use the other columns such as the breed in the neural network if you so chose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters_to_matrix(character_data):\n",
    "    character_data = [[character_lookup[chr] for chr in c] for c in character_data]\n",
    "    padded_character_data = keras.utils.pad_sequences(character_data, maxlen = max_length+1)\n",
    "    text_matrix = keras.utils.to_categorical(padded_character_data, num_classes = num_characters)\n",
    "    return text_matrix\n",
    "\n",
    "expanded_data = pet_data.explode(\"subsequences\")\n",
    "character_data = expanded_data[\"subsequences\"].tolist()\n",
    "random.shuffle(character_data)\n",
    "text_matrix = characters_to_matrix(character_data)\n",
    "\n",
    "x_name = text_matrix[:,range(max_length),:]\n",
    "y_name = text_matrix[:,max_length,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we start the neural network part. Below is the model architecture definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(max_length, num_characters)),\n",
    "        layers.LSTM(32, return_sequences = True),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_characters, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_name, y_name, batch_size = 64, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last we save the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8150c625a63ac57475fcc2a1d303ce8eece2765264f9ecef0b57ffda11156453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
