{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import string\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_list = list(string.ascii_lowercase) + [\".\",\"-\",\" \",\"+\"]\n",
    "character_lookup = dict(zip(character_list, range(len(character_list))))\n",
    "max_length = 10\n",
    "num_characters = len(character_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_data = pd.read_csv(\"seattle_pet_licenses.csv\", dtype = {\"Animal's Name\": str, 'Species': str,'Primary Breed': str,\n",
    "                                                      'Secondary Breed': str},\n",
    "                                                      usecols=[\"Animal's Name\",'Species',\n",
    "                                                      'Primary Breed','Secondary Breed'],\n",
    "                                                      keep_default_na=False)\n",
    "pet_data.columns = [\"name\",\"species\",\"primary_breed\",\"secondary_breed\"]\n",
    "\n",
    "for c in pet_data.columns:\n",
    "    pet_data[c] = [s.lower() for s in pet_data[c]]\n",
    "\n",
    "pet_data = pet_data[(pet_data[\"name\"] != '') & (pet_data[\"species\"] != '')]\n",
    "pet_data = pet_data[pet_data[\"name\"].str.match(\"^[ \\\\.a-z-]+$\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subsequences(name, **kwargs):\n",
    "    value = kwargs\n",
    "    characters = name + '+'\n",
    "    subsequences = [list(characters[0:(i+1)]) for i in range(len(characters))]\n",
    "    for i, s in enumerate(subsequences):\n",
    "        full_dict = kwargs.copy()\n",
    "        full_dict.update({'subsequence': s})\n",
    "        subsequences[i] = full_dict\n",
    "    return subsequences\n",
    "\n",
    "subsequences = [make_subsequences(pet_data.iloc[i][\"name\"], species = pet_data.iloc[i][\"species\"]) for i in range(len(pet_data))]\n",
    "subsequences = list(itertools.chain.from_iterable(subsequences))\n",
    "random.shuffle(subsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characters_to_matrix(character_data):\n",
    "    character_data = [[character_lookup[chr] for chr in c] for c in character_data]\n",
    "    padded_character_data = keras.utils.pad_sequences(character_data, maxlen = max_length+1)\n",
    "    text_matrix = keras.utils.to_categorical(padded_character_data, num_classes = num_characters)\n",
    "    return text_matrix\n",
    "\n",
    "character_data = [s['subsequence'] for s in subsequences]\n",
    "text_matrix = characters_to_matrix(character_data)\n",
    "\n",
    "x_name = text_matrix[:,range(max_length),:]\n",
    "y_name = text_matrix[:,max_length,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(max_length, num_characters)),\n",
    "        layers.LSTM(32, return_sequences = True),\n",
    "        layers.LSTM(32),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(num_characters, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "5748/5748 [==============================] - 43s 7ms/step - loss: 1.9132\n",
      "Epoch 2/25\n",
      "5748/5748 [==============================] - 37s 6ms/step - loss: 1.9118\n",
      "Epoch 3/25\n",
      "5748/5748 [==============================] - 37s 6ms/step - loss: 1.9137\n",
      "Epoch 4/25\n",
      "5748/5748 [==============================] - 40s 7ms/step - loss: 1.9153\n",
      "Epoch 5/25\n",
      "5748/5748 [==============================] - 39s 7ms/step - loss: 1.9137\n",
      "Epoch 6/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9161\n",
      "Epoch 7/25\n",
      "5748/5748 [==============================] - 36s 6ms/step - loss: 1.9208\n",
      "Epoch 8/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9237\n",
      "Epoch 9/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9252\n",
      "Epoch 10/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9289\n",
      "Epoch 11/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9397\n",
      "Epoch 12/25\n",
      "5748/5748 [==============================] - 36s 6ms/step - loss: 1.9406\n",
      "Epoch 13/25\n",
      "5748/5748 [==============================] - 32s 6ms/step - loss: 1.9481\n",
      "Epoch 14/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9501\n",
      "Epoch 15/25\n",
      "5748/5748 [==============================] - 32s 6ms/step - loss: 1.9530\n",
      "Epoch 16/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9495\n",
      "Epoch 17/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9544\n",
      "Epoch 18/25\n",
      "5748/5748 [==============================] - 37s 6ms/step - loss: 1.9497\n",
      "Epoch 19/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9675\n",
      "Epoch 20/25\n",
      "5748/5748 [==============================] - 34s 6ms/step - loss: 1.9713\n",
      "Epoch 21/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9649\n",
      "Epoch 22/25\n",
      "5748/5748 [==============================] - 37s 6ms/step - loss: 1.9827\n",
      "Epoch 23/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9776\n",
      "Epoch 24/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9814\n",
      "Epoch 25/25\n",
      "5748/5748 [==============================] - 33s 6ms/step - loss: 1.9701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b732a340d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_name, y_name, batch_size = 64, epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8150c625a63ac57475fcc2a1d303ce8eece2765264f9ecef0b57ffda11156453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
